#---
## ----------------------------------------------------------------------------------------
## -- Docs: https://github.com/cluster-apps-on-docker/spark-standalone-cluster-on-docker --
## ----------------------------------------------------------------------------------------
#version: "3.6"
#volumes:
#  shared-workspace:
#    name: "hadoop-distributed-file-system"
#    driver: local
#services:
#  jupyterlab:
#    image: andreper/jupyterlab:3.0.0-spark-3.0.0
#    container_name: jupyterlab
#    ports:
#      - 8888:8888
#      - 4040:4040
#    volumes:
#      - shared-workspace:/opt/workspace
#  spark-master:
#    image: andreper/spark-master:3.0.0
#    container_name: spark-master
#    ports:
#      - 8080:8080
#      - 7077:7077
#    volumes:
#      - shared-workspace:/opt/workspace
#      - ./zeppelin/jars:/opt/spark/jars
#  spark-worker-1:
#    image: andreper/spark-worker:3.0.0
#    container_name: spark-worker-1
#    environment:
#      - SPARK_WORKER_CORES=1
#      - SPARK_WORKER_MEMORY=512m
#    ports:
#      - 8081:8081
#    volumes:
#      - shared-workspace:/opt/workspace
#      - ./zeppelin/jars:/opt/spark/jars
#    depends_on:
#      - spark-master
#

 version: '3'

 services:
   neo4j:
     image: neo4j:5.4.0-enterprise
     volumes:
       - ./app/data_io:/import
     ports:
       - 7474:7474
       - 7687:7687
     environment:
       NEO4J_AUTH: neo4j/password
       NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
       NEO4J_PLUGINS: '["graph-data-science"]'
       NEO4J_dbms_security_procedures_unrestricted: "gds.*"
